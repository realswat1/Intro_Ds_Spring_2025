{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "742eff1a-4319-43ff-ad37-9d63c68000ba",
   "metadata": {},
   "source": [
    "# Project 1 - Part II: Data Science with NumPy & Pandas\n",
    "# MATH 014 - Introduction to Data Science\n",
    "# Student Name: Godfred Asamoah \n",
    "# Student ID: @03054184  \n",
    "# Due Date: 03-21-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c3809-7a55-4abc-bb83-05fac65747c8",
   "metadata": {},
   "source": [
    "## Part 1: Understanding NumPy & Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ffcb4e-df96-419b-a792-fe69276b46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68ca4e-6e7f-4278-bd5f-23c12a12ab59",
   "metadata": {},
   "source": [
    "### TASK 1: NUMPY BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda21ff8-609d-4bce-8a49-3eec96a228b8",
   "metadata": {},
   "source": [
    "#### 1.1 Numpy Array Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31235114-9a91-4d41-a31e-697143215553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D array of integers from 1 to 20:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    }
   ],
   "source": [
    "# 1D Numpy array of ints from 1 - 20\n",
    "array_1d = np.arange(1, 21)\n",
    "print(\"1D array of integers from 1 to 20:\")\n",
    "print(array_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3016fa7a-3b33-4c66-94db-df6751868f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0002D array (5x4) of random nums:\n",
      "[[0.55819402 0.42807249 0.71645839 0.55550102]\n",
      " [0.26618682 0.05665466 0.51624707 0.37177895]\n",
      " [0.4489265  0.26396615 0.88703869 0.03521425]\n",
      " [0.49634035 0.31259991 0.75335523 0.4153651 ]\n",
      " [0.20677948 0.96260964 0.27191062 0.52292157]]\n"
     ]
    }
   ],
   "source": [
    "# 2D Numpy array (5x4) filled with random numbers \n",
    "array_2d = np.random.random((5, 4))\n",
    "print(\"\\2D array (5x4) of random nums:\")\n",
    "print(array_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085dfa9-ed42-4d82-b6e5-346999365fb2",
   "metadata": {},
   "source": [
    "#### 1.2 Array Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef842b39-2e7a-4101-bf54-313b3963820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Even nums from 1D array:\n",
      "[ 2  4  6  8 10 12 14 16 18 20]\n"
     ]
    }
   ],
   "source": [
    "# Extract even nums from 1D array\n",
    "even_nums = array_1d[array_1d % 2 == 0]\n",
    "print(\"\\n Even nums from 1D array:\")\n",
    "print(even_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdbd59d8-7595-48f0-821c-7386de5d63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2nd & 4th rows from 2D array:\n",
      "[[0.26618682 0.05665466 0.51624707 0.37177895]\n",
      " [0.49634035 0.31259991 0.75335523 0.4153651 ]]\n"
     ]
    }
   ],
   "source": [
    "# Extract 2nd & 4th row from 2D array\n",
    "second_fourth_rows = array_2d[[1, 3], :]\n",
    "print(\"\\n2nd & 4th rows from 2D array:\")\n",
    "print(second_fourth_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef369d2e-5b10-474f-a5a8-f695bcf45afd",
   "metadata": {},
   "source": [
    "#### 1.3 Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e60d0973-24e0-47f1-b516-c0193b9a3875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Array with step of 10 from 10 - 100:\n",
      "[ 10  20  30  40  50  60  70  80  90 100]\n"
     ]
    }
   ],
   "source": [
    "# Numpy array of nums from 10 - 100 with step 10\n",
    "array_10step = np.arange(10, 101, 10)\n",
    "print(\"\\nArray with step of 10 from 10 - 100:\")\n",
    "print(array_10step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e04299-0c58-48ca-abf7-26930e39262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Squared array:\n",
      "[  100   400   900  1600  2500  3600  4900  6400  8100 10000]\n",
      "\n",
      "Square root of array:\n",
      "[ 3.16227766  4.47213595  5.47722558  6.32455532  7.07106781  7.74596669\n",
      "  8.36660027  8.94427191  9.48683298 10.        ]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise square and square root ops on array\n",
    "array_squared = np.square(array_10step)\n",
    "array_sqrt = np.sqrt(array_10step)\n",
    "print(\"\\nSquared array:\")\n",
    "print(array_squared)\n",
    "print(\"\\nSquare root of array:\")\n",
    "print(array_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af4c74-9681-4398-be21-686c8c941ed1",
   "metadata": {},
   "source": [
    "#### 1.4 Statistical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d58abe-102d-4775-a638-624e15d316d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0003by3 array of random ints between 1 and 50:\n",
      "[[44 33 49]\n",
      " [37 16 32]\n",
      " [ 2 19 47]]\n"
     ]
    }
   ],
   "source": [
    "# 3x3 NumPy array of random integers between 1 and 50\n",
    "array_3by3 = np.random.randint(1, 51, size=(3, 3))\n",
    "print(\"\\3by3 array of random ints between 1 and 50:\")\n",
    "print(array_3by3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bf30d-5eab-4294-81dc-7531405e3014",
   "metadata": {},
   "source": [
    "# Mean, median & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "273007c4-17a2-43aa-a906-c9de0c4c67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean: 31.0\n",
      "\n",
      "Mdian: 33.0\n",
      "\n",
      "Standard Deviation: 14.907119849998598\n"
     ]
    }
   ],
   "source": [
    "mean_val = np.mean(array_3by3)\n",
    "median_val = np.median(array_3by3)\n",
    "std_val = np.std(array_3by3)\n",
    "\n",
    "print(f\"\\nMean: {mean_val}\")\n",
    "print(f\"\\nMdian: {median_val}\")\n",
    "print(f\"\\nStandard Deviation: {std_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e449895-dc56-408b-a1ba-c86f25c32733",
   "metadata": {},
   "source": [
    "### TASK 2: PANDAS BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398401f-e293-45e6-96e8-f118f46c7526",
   "metadata": {},
   "source": [
    "#### 2.1 Data Loading & Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "849db532-c10b-4df0-bb2d-891ca7f8b40e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'project1_part2_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject1_part2_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'project1_part2_data.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('project1_part2_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddd08f-4f79-4102-9819-8fca6d159c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows\n",
    "print(\"\\nFirst 5 rows of dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463b86b-3b23-4f9d-8adc-995b902c7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info and missing values check\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84771473-ab9c-4fb0-8553-b77abc61d1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Original data copy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_new \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Original data copy\n",
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3150c-5231-4c49-9fdf-19aca8292237",
   "metadata": {},
   "source": [
    "#### 2.2 Data Selection & Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddd4e4e8-0af1-40e4-b4b9-b863df2c6a3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# name and salary columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m name_salary_df \u001b[38;5;241m=\u001b[39m df_new[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mName and Salary columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(name_salary_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "# name and salary columns\n",
    "name_salary_df = df_new[['Name', 'Salary']]\n",
    "print(\"\\nName and Salary columns:\")\n",
    "print(name_salary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45c9fce9-9bf4-419b-8931-0dcb0a54e923",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# employees earning more than $50,000\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m high_earners_50k \u001b[38;5;241m=\u001b[39m df_new[df_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m50000\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEmployees earning more than $50,000:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(high_earners_50k)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "# employees earning more than $50,000\n",
    "high_earners_50k = df_new[df_new['Salary'] > 50000]\n",
    "print(\"\\nEmployees earning more than $50,000:\")\n",
    "print(high_earners_50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab876050-c02d-42d6-a6e9-35d476409527",
   "metadata": {},
   "source": [
    "#### 2.3 Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a583bf39-b60d-4874-a26b-3534bb8e3df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Average salary of employees: $82143.47\n"
     ]
    }
   ],
   "source": [
    "# average salary of employees \n",
    "avg_salary = df_new['Salary'].mean()\n",
    "print(f\"\\nAverage salary of employees: ${avg_salary:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba81e8f1-43e2-4b7d-96b7-71daa3d44185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Number of employees in each department:\n",
      ",Department\n",
      ",HR            5\n",
      ",Operations    4\n",
      ",Sales         4\n",
      ",Finance       3\n",
      ",IT            2\n",
      ",Marketing     2\n",
      ",Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# number of employees in each department\n",
    "dept_count = df_new['Department'].value_counts()\n",
    "print(\"\\nNumber of employees in each department:\")\n",
    "print(dept_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862918c9-55a0-42ce-9574-7d65db5cc644",
   "metadata": {},
   "source": [
    "#### 2.4 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3dcec88-c95e-40a4-9a75-58820a0a8d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Data after cleaning:\n",
      ",    ID               Name   Age         Salary  Department     Position  \\\n",
      ",0    1      Alice Johnson  49.0   46910.000000  Operations   Consultant   \n",
      ",1    2      Michael Smith  28.0   40206.000000          IT      Manager   \n",
      ",2    3      Emma Williams  30.0   63419.000000       Sales      Analyst   \n",
      ",3    4        David Brown  29.0   90636.000000          HR    Executive   \n",
      ",4    5       Olivia Jones  33.0   82143.473684   Marketing   Consultant   \n",
      ",5    6       James Garcia  55.0   94268.000000     Finance  Coordinator   \n",
      ",6    7    Sophia Martinez  54.0   58141.000000  Operations      Manager   \n",
      ",7    8  Benjamin Anderson  44.0  111910.000000   Marketing      Manager   \n",
      ",8    9   Charlotte Thomas  45.0   96044.000000       Sales    Executive   \n",
      ",10  11      Amelia Taylor  56.0   73827.000000  Operations   Consultant   \n",
      ",11  12      Matthew Moore  43.0   95820.000000     Finance  Coordinator   \n",
      ",12  13       Isabella Lee  48.0  102623.000000          IT      Manager   \n",
      ",13  14       Ethan Harris  56.0  115450.000000          HR      Manager   \n",
      ",14  15          Mia Clark  22.0   62299.000000          HR   Consultant   \n",
      ",15  16    Alexander Lewis  56.0   83585.000000  Operations    Developer   \n",
      ",16  17      Harper Walker  58.0  104044.000000     Finance   Consultant   \n",
      ",17  18       William Hall  35.0   82557.000000       Sales      Manager   \n",
      ",18  19       Evelyn Young  24.0   89080.000000       Sales   Consultant   \n",
      ",19  20        Henry Allen  22.0   42693.000000          HR      Manager   \n",
      ",\n",
      ",    Work Experience (Years) Education Level   Salary_Bonus  \n",
      ",0                        13             PhD   51601.000000  \n",
      ",1                         9       Associate   44226.600000  \n",
      ",2                        15             PhD   69760.900000  \n",
      ",3                        13      Bachelor's   99699.600000  \n",
      ",4                         1         Diploma   90357.821053  \n",
      ",5                         7         Diploma  103694.800000  \n",
      ",6                         9        Master's   63955.100000  \n",
      ",7                        24      Bachelor's  123101.000000  \n",
      ",8                         1      Bachelor's  105648.400000  \n",
      ",10                        8         Diploma   81209.700000  \n",
      ",11                       24             PhD  105402.000000  \n",
      ",12                       11      Bachelor's  112885.300000  \n",
      ",13                       19       Associate  126995.000000  \n",
      ",14                       17      Bachelor's   68528.900000  \n",
      ",15                        8       Associate   91943.500000  \n",
      ",16                        3       Associate  114448.400000  \n",
      ",17                        3      Bachelor's   90812.700000  \n",
      ",18                        1             PhD   97988.000000  \n",
      ",19                        5        Master's   46962.300000  \n",
      ",\n",
      ",Missing values after cleaning:\n",
      ",ID                         0\n",
      ",Name                       0\n",
      ",Age                        0\n",
      ",Salary                     0\n",
      ",Department                 0\n",
      ",Position                   0\n",
      ",Work Experience (Years)    0\n",
      ",Education Level            0\n",
      ",Salary_Bonus               0\n",
      ",dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# replacing missing salary values with mean salary\n",
    "df_new['Salary'] = df_new['Salary'].fillna(df_new['Salary'].mean())\n",
    "\n",
    "# drop rows with missing ages\n",
    "df_new.dropna(subset=['Age'], inplace=True)\n",
    "\n",
    "print(\"\\nData after cleaning:\")\n",
    "print(df_new)\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df_new.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3e08c-da41-4664-af5c-98f1dfb7a8b7",
   "metadata": {},
   "source": [
    "### TASK 3: COMBINED NUMPY & PANDAS OPERATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece7092-3458-4857-b932-c17691e7e4c0",
   "metadata": {},
   "source": [
    "#### 3.1 Converting a Column to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0c9ca1d-5bf1-4cc1-9475-0a6da21f4880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Salary column as NumPy array:\n",
      ",[ 46910.          40206.          63419.          90636.\n",
      ",  82143.47368421  94268.          58141.         111910.\n",
      ",  96044.          73827.          95820.         102623.\n",
      ", 115450.          62299.          83585.         104044.\n",
      ",  82557.          89080.          42693.        ]\n"
     ]
    }
   ],
   "source": [
    "# extracted salary column as numpy array\n",
    "salary_array = df_new['Salary'].to_numpy()\n",
    "print(\"\\nSalary column as NumPy array:\")\n",
    "print(salary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1116bda4-4535-4be4-9311-ab313bcd90b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Standard deviation of salaries: $22310.35\n"
     ]
    }
   ],
   "source": [
    "# standard deviation of salary array using numpy\n",
    "salary_std = np.std(salary_array)\n",
    "print(f\"\\nStandard deviation of salaries: ${salary_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d4ed0-fb0d-47ce-aea6-c03d58f3c12d",
   "metadata": {},
   "source": [
    "#### 3.2 New Column Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01ac6eb7-5e3b-4026-b2d6-eb0c7b6955ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",data with Salary_Bonus column:\n",
      ",                 Name         Salary   Salary_Bonus\n",
      ",0       Alice Johnson   46910.000000   51601.000000\n",
      ",1       Michael Smith   40206.000000   44226.600000\n",
      ",2       Emma Williams   63419.000000   69760.900000\n",
      ",3         David Brown   90636.000000   99699.600000\n",
      ",4        Olivia Jones   82143.473684   90357.821053\n",
      ",5        James Garcia   94268.000000  103694.800000\n",
      ",6     Sophia Martinez   58141.000000   63955.100000\n",
      ",7   Benjamin Anderson  111910.000000  123101.000000\n",
      ",8    Charlotte Thomas   96044.000000  105648.400000\n",
      ",10      Amelia Taylor   73827.000000   81209.700000\n",
      ",11      Matthew Moore   95820.000000  105402.000000\n",
      ",12       Isabella Lee  102623.000000  112885.300000\n",
      ",13       Ethan Harris  115450.000000  126995.000000\n",
      ",14          Mia Clark   62299.000000   68528.900000\n",
      ",15    Alexander Lewis   83585.000000   91943.500000\n",
      ",16      Harper Walker  104044.000000  114448.400000\n",
      ",17       William Hall   82557.000000   90812.700000\n",
      ",18       Evelyn Young   89080.000000   97988.000000\n",
      ",19        Henry Allen   42693.000000   46962.300000\n"
     ]
    }
   ],
   "source": [
    "# new column where each employee gets a 10% increase in salary\n",
    "df_new['Salary_Bonus'] = df_new['Salary'] * 1.1 \n",
    "print(\"\\ndata with Salary_Bonus column:\")\n",
    "print(df_new[['Name', 'Salary', 'Salary_Bonus']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69939c6b-fff3-46d4-abb6-8e7a33828a24",
   "metadata": {},
   "source": [
    "#### 3.3 Grouping, Summarization & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f82daaa4-5bd7-4508-9032-b9cbb5c80024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ",Total salary expense per deparment:\n",
      ",Department\n",
      ",Finance       294132.000000\n",
      ",HR            311078.000000\n",
      ",IT            142829.000000\n",
      ",Marketing     194053.473684\n",
      ",Operations    262463.000000\n",
      ",Sales         331100.000000\n",
      ",Name: Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Grouped data by department\n",
    "# total salary expense per department\n",
    "dept_salary_total = df_new.groupby('Department')['Salary'].sum()\n",
    "print(\"\\nTotal salary expense per deparment:\")\n",
    "print(dept_salary_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd177636-a5e6-4725-b797-ffac4c30e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cleaned csv\n",
    "df_new.to_csv('project1_part2_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc5b759-ca73-4821-9595-8a40fb47f411",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(df_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHappiness Score\u001b[39m\u001b[38;5;124m'\u001b[39m], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Happiness Scores\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHappiness Score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of Happiness Score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_new['Happiness Score'], kde=True, color='green')\n",
    "plt.title('Distribution of Happiness Scores')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5a4da-476e-481b-944c-1948e80fe3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb62c6e-3484-4edc-92e3-0b046c3cd33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
